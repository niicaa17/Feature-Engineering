# Oversampling dan Undersampling

Hi calon engineer masa depan! ðŸš€  
Pada tahap ini kita membahas permasalahan umum dalam machine learning yaitu **imbalanced dataset** dan teknik penanganannya.

---

## ðŸ“Œ Imbalanced Dataset

Imbalanced dataset adalah kondisi ketika jumlah data pada satu kelas jauh lebih banyak dibanding kelas lainnya.

Contoh:
- Kelas mayoritas: 95%
- Kelas minoritas: 5%

Masalah yang muncul:
- Model cenderung memprediksi kelas mayoritas
- Akurasi terlihat tinggi tetapi performa sebenarnya buruk
- Kelas minoritas sering salah diprediksi
- Akurasi bukan metrik yang tepat â†’ gunakan precision, recall, F1-score

---

## âš–ï¸ Tingkat Ketidakseimbangan

Secara umum tingkat imbalance dapat dibagi menjadi:
- Ringan
- Sedang
- Parah

Disarankan tetap membuat **baseline model** terlebih dahulu sebelum melakukan teknik penyeimbangan data.

---

# ðŸ”¼ Oversampling

Oversampling adalah teknik **menambah jumlah data kelas minoritas** agar seimbang dengan kelas mayoritas.

## âœ… Tujuan
- Memberi model lebih banyak contoh kelas minoritas
- Mengurangi bias ke kelas mayoritas

---

## ðŸ”¹ Random Oversampling

Menyalin (duplicate) data minoritas secara acak hingga jumlahnya seimbang.

**Contoh:**
- Mayoritas = 100 data
- Minoritas = 10 data
- Minoritas diduplikasi menjadi 100

### Kelebihan
- Mudah diterapkan
- Cepat
- Komputasi ringan

### Kekurangan
- Risiko overfitting
- Model bisa â€œmenghafalâ€ data duplikat

---

## ðŸ”¹ SMOTE (Synthetic Minority Over-sampling Technique)

SMOTE membuat **data sintetis baru** dari kelas minoritas dengan interpolasi antar titik data.

### Cara kerja
- Memilih dua titik minoritas
- Membuat titik baru di antara keduanya
- Menambah variasi data minoritas

### Kelebihan
- Mengurangi overfitting
- Data tidak sekadar duplikat
- Variasi lebih baik

### Kekurangan
- Lebih kompleks
- Bisa menghasilkan data sintetis yang kurang realistis jika distribusi buruk

---

# ðŸ”½ Undersampling

Undersampling adalah teknik **mengurangi jumlah data kelas mayoritas** agar seimbang dengan kelas minoritas.

---

## ðŸ”¹ Random Undersampling

Menghapus data mayoritas secara acak.

**Contoh:**
- Mayoritas = 100
- Minoritas = 10
- Mayoritas dipotong menjadi 10

### Kelebihan
- Sederhana
- Cepat
- Dataset lebih kecil â†’ training lebih cepat

### Kekurangan
- Kehilangan informasi penting
- Risiko underfitting
- Pola mayoritas bisa hilang

---

## ðŸ”¹ Cluster Centroids

Menggunakan algoritma clustering (misal K-Means) untuk:
- Mengelompokkan data mayoritas
- Mengambil centroid sebagai wakil cluster
- Mengurangi data tanpa menghapus pola utama

### Kelebihan
- Representasi mayoritas lebih terjaga
- Lebih cerdas dari random undersampling

### Kekurangan
- Komputasi lebih berat
- Bisa kehilangan variasi pola
- Tidak selalu cocok untuk data sangat kompleks

---

# ðŸ§  Ringkasan Strategi

| Metode | Cara | Risiko |
|--------|--------|---------|
| Oversampling | Tambah data minoritas | Overfitting |
| SMOTE | Data sintetis minoritas | Data tidak realistis |
| Undersampling | Kurangi mayoritas | Kehilangan informasi |
| Cluster Centroids | Representasi cluster | Bias sampling |

---

# ðŸŽ¯ Rekomendasi Praktis

- âœ… Bangun baseline model dulu
- âœ… Gunakan metrik selain akurasi
- âœ… Coba beberapa teknik sampling
- âœ… Validasi dengan cross-validation
- âœ… Jika memungkinkan â†’ kumpulkan data asli tambahan
- âš ï¸ Data sintetis bukan pengganti data nyata

---

> Imbalanced dataset adalah masalah umum â€” teknik sampling adalah alat bantu, bukan solusi utama. Data berkualitas tetap yang paling penting.
